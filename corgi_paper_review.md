# CoRGI Paper Review

**Paper:** CoRGI: Verified Chain-of-Thought Reasoning with Post-hoc Visual Grounding  
**Authors:** Shixin Yi, Lin Shang  
**Link:** https://arxiv.org/abs/2508.00378  
**Reviewer:** CoRGI Implementation Team  
**Date:** December 2024

---

## ğŸ“‹ Tá»•ng quan

### Má»¥c tiÃªu cá»§a Paper

Paper giáº£i quyáº¿t váº¥n Ä‘á» **hallucination** (áº£o giÃ¡c) trong cÃ¡c Vision-Language Models (VLMs) khi thá»±c hiá»‡n multimodal reasoning. CÃ¡c VLMs hiá»‡n táº¡i thÆ°á»ng táº¡o ra cÃ¡c giáº£i thÃ­ch nghe cÃ³ váº» há»£p lÃ½ nhÆ°ng khÃ´ng thá»±c sá»± dá»±a trÃªn ná»™i dung hÃ¬nh áº£nh.

### ÄÃ³ng gÃ³p chÃ­nh

1. **XÃ¡c Ä‘á»‹nh váº¥n Ä‘á» "Single-Look Bias"** - MÃ´ hÃ¬nh chá»‰ nhÃ¬n áº£nh má»™t láº§n, sau Ä‘Ã³ reasoning dá»±a hoÃ n toÃ n trÃªn language model
2. **Äá» xuáº¥t CoRGI Framework** - Má»™t pipeline 3 giai Ä‘oáº¡n Ä‘á»ƒ verify tá»«ng bÆ°á»›c reasoning vá»›i visual evidence
3. **Thiáº¿t káº¿ VEVM Module** - Visual Evidence Verification Module vá»›i cÃ¡c thÃ nh pháº§n modular

---

## ğŸ” PhÃ¢n tÃ­ch Chi tiáº¿t

### 1. Váº¥n Ä‘á» Ä‘Æ°á»£c giáº£i quyáº¿t

#### Single-Look Bias

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  TRADITIONAL VLM ARCHITECTURE (Problematic)                     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  Image â”€â”€â”¬â”€â”€â–º Visual Encoder â”€â”€â–º Fixed Representation          â”‚
â”‚          â”‚                              â”‚                       â”‚
â”‚          â”‚                              â–¼                       â”‚
â”‚          â”‚                    Language Model (LLM)              â”‚
â”‚          â”‚                              â”‚                       â”‚
â”‚          â”‚         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚          â”‚         â”‚  Step 1 â†’ Step 2 â†’ Step 3 â†’ Answer   â”‚     â”‚
â”‚          â”‚         â”‚  (Autoregressive, never re-consults  â”‚     â”‚
â”‚          â”‚         â”‚   the image!)                        â”‚     â”‚
â”‚          â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â”‚          â”‚                                                      â”‚
â”‚          â””â”€â”€â–º âŒ Image khÃ´ng Ä‘Æ°á»£c "nhÃ¬n láº¡i" trong reasoning    â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Háº­u quáº£:**
- Reasoning cÃ³ thá»ƒ fluent vá» máº·t ngÃ´n ngá»¯ nhÆ°ng khÃ´ng faithful vá»›i visual content
- Hallucination: mÃ´ hÃ¬nh "bá»‹a" thÃ´ng tin khÃ´ng cÃ³ trong áº£nh
- CÃ¡c bÆ°á»›c reasoning drift away khá»i thá»±c táº¿ visual

#### Táº¡i sao khÃ´ng dÃ¹ng Iterative Grounding?

| Approach | Pros | Cons |
|----------|------|------|
| Iterative Grounding | Real-time verification | ÄÃ²i há»i architecture redesign, expensive training |
| **Post-hoc Verification (CoRGI)** | Lightweight, modular, compatible vá»›i VLMs hiá»‡n cÃ³ | Sequential, khÃ´ng real-time correction |

---

### 2. PhÆ°Æ¡ng phÃ¡p: CoRGI Pipeline

#### Stage 1: Reasoning Chain Generation

**Má»¥c Ä‘Ã­ch:** Táº¡o chuá»—i reasoning Ä‘a bÆ°á»›c

```
Input: Image I + Question Q
       â†“
VLM (e.g., Qwen-2.5VL 7B)
       â†“
Output: R = {râ‚, râ‚‚, ..., râ‚™}
```

**Nháº­n xÃ©t:**
- âœ… Sá»­ dá»¥ng foundation VLM máº¡nh Ä‘á»ƒ táº¡o reasoning plan
- âœ… Má»—i step lÃ  má»™t logical assertion
- âš ï¸ á» stage nÃ y, reasoning váº«n cÃ³ thá»ƒ bá»‹ hallucination (sáº½ Ä‘Æ°á»£c verify á»Ÿ Stage 2)

#### Stage 2: Visual Evidence Verification (VEVM)

**ÄÃ¢y lÃ  pháº§n core cá»§a framework, gá»“m 3 sub-modules:**

##### 2.1 Relevance Classification

```python
# Pseudo-code
class RelevanceClassifier(nn.Module):
    def __init__(self):
        self.mlp = MLP(hidden_dim=...)
    
    def forward(self, reasoning_step):
        logit = self.mlp(reasoning_step)
        sigmoid_value = torch.sigmoid(logit)
        
        if sigmoid_value < threshold:
            return "non_visual", 0  # Bypass
        else:
            importance = piecewise_mapping(sigmoid_value)
            return "visual", importance  # e.g., "importance: 75%"
```

**Ã nghÄ©a:**
- KhÃ´ng pháº£i táº¥t cáº£ reasoning steps Ä‘á»u cáº§n visual verification
- Má»™t sá»‘ steps thuáº§n tÃºy abstract reasoning (e.g., "Based on the previous observations...")
- Classifier quyáº¿t Ä‘á»‹nh **IF** vÃ  **HOW MUCH** cáº§n verify

##### 2.2 RoI Selection

**Model:** Grounding DINO (zero-shot object detection)

```
Input: Reasoning step text (e.g., "The person is wearing a red shirt")
       â†“
Grounding DINO
       â†“
Output: Bounding boxes cho regions liÃªn quan
```

**Æ¯u Ä‘iá»ƒm:**
- Zero-shot: khÃ´ng cáº§n train thÃªm
- Dynamically identify regions based on text
- Spatial precision cho evidence extraction

##### 2.3 VLM-based Visual Evidence Extraction

```
Input: 
  - RoI crops tá»« image
  - Reasoning step (Ä‘á»ƒ condition)
       â†“
VLM as "Fact Checker"
       â†“
Output: Textual description E = {eâ‚, eâ‚‚, ..., eâ‚™}
```

**Key insight:** DÃ¹ng VLM hiá»‡n cÃ³ thay vÃ¬ train model má»›i â†’ practical vÃ  scalable

#### Stage 3: Final Answer Synthesis

```
Prompt = {
    "Question": Q,
    "Reasoning Chain": R,
    "Visual Evidence": E (vá»›i importance scores)
}
       â†“
VLM
       â†“
Final Answer (grounded)
```

**Lá»£i Ã­ch:**
- Model cÃ³ cáº£ "thoughts" VÃ€ "evidence"
- Reduce hallucination tendency
- More robust conclusions

---

### 3. Káº¿t quáº£ Thá»±c nghiá»‡m

#### 3.1 Datasets vÃ  Models

| Benchmark | Focus |
|-----------|-------|
| VCR | Visual Commonsense Reasoning |
| ScienceQA | Scientific knowledge |
| MMMU | Multi-discipline exam problems |
| MathVista | Math-based reasoning |
| HallusionBench | Hallucination stress testing |

**VLM Backbones:** Qwen-2.5VL-7B, LLaVA-1.6-7B, Gemma3-12B

#### 3.2 Performance Analysis

##### Improvement Summary

| Model | Best Improvement | Dataset |
|-------|-----------------|---------|
| LLaVA-1.6 | **+12.9 points** | VCR QAâ†’R |
| Qwen-2.5VL | **+8.4 points** | VCR Qâ†’AR |
| Gemma3-12B | **+8.3 points** | VCR Qâ†’AR |

##### Key Observations

1. **Weaker models benefit more:** LLaVA-1.6 cÃ³ built-in grounding yáº¿u hÆ¡n â†’ gains lá»›n nháº¥t tá»« post-hoc verification

2. **Strong models still benefit:** Ngay cáº£ Qwen-2.5VL (strong) váº«n cÃ³ gains, cho tháº¥y má»i VLM Ä‘á»u cÃ³ unsupported reasoning steps

3. **Generalization:** CoRGI works across diverse tasks (science, math, commonsense, hallucination testing)

#### 3.3 Ablation Study Insights

```
Full CoRGI = Best Performance
     â†“
Remove Relevance Classifier â†’ â†“ 1.9-2.4 points
Remove RoI Selection â†’ â†“ 1.3-2.5 points  
Remove Reasoning Conditioning â†’ â†“ 0.2-2.2 points
Remove All Visual Evidence â†’ â†“ 1.7-2.0 points (= CoT baseline)
```

**Káº¿t luáº­n:** Má»—i component Ä‘á»u cáº§n thiáº¿t, cÃ³ synergistic effect khi combine

---

### 4. So sÃ¡nh vá»›i Implementation cá»§a chÃºng ta

#### 4.1 TÆ°Æ¡ng Ä‘á»“ng

| Paper CoRGI | Our Implementation |
|-------------|-------------------|
| 3-stage pipeline | âœ… V2 pipeline vá»›i merged Phase 1+2 |
| Visual grounding tá»« text | âœ… Qwen/Florence for grounding |
| Evidence extraction with VLM | âœ… SmolVLM2/Florence OCR |
| Synthesis with all evidence | âœ… Phase 4 synthesis |

#### 4.2 KhÃ¡c biá»‡t vÃ  Cáº£i tiáº¿n

| Aspect | Paper | Our V2 Implementation |
|--------|-------|----------------------|
| **Reasoning + Grounding** | 2 separate stages | Merged vÃ o 1 call (faster) |
| **Evidence Type** | VLM decides implicitly | Explicit `need_object` / `need_text` flags |
| **Relevance Classifier** | Trained MLP | Rule-based hoáº·c implicit tá»« structured output |
| **RoI Selector** | Grounding DINO | Qwen built-in grounding HOáº¶C Florence |
| **Latency** | ~10s+ estimated | ~6.3s (37% faster) |
| **Memory** | Multiple models | Reuse reasoning model (67% less VRAM) |

#### 4.3 CÃ¡c cáº£i tiáº¿n tiá»m nÄƒng tá»« Paper

1. **Importance Scoring:** Paper dÃ¹ng importance percentage tá»« classifier â†’ cÃ³ thá»ƒ add vÃ o synthesis prompt

2. **Explicit Relevance Classification:** Train má»™t classifier nháº¹ Ä‘á»ƒ filter non-visual steps

3. **Step-level Verification:** Verify tá»«ng step chi tiáº¿t hÆ¡n thay vÃ¬ batch

---

## ğŸ’¡ Insights vÃ  Lessons Learned

### Äiá»ƒm máº¡nh cá»§a Paper

1. **Practical approach:** KhÃ´ng cáº§n retrain VLM, chá»‰ add verification layer
2. **Modular design:** CÃ³ thá»ƒ swap components easily
3. **Comprehensive evaluation:** 5 benchmarks, 3 VLMs, ablation studies
4. **Clear problem definition:** "Single-look bias" lÃ  má»™t framing tá»‘t

### Äiá»ƒm yáº¿u vÃ  Limitations

1. **Sequential nature:** Errors early in chain khÃ´ng thá»ƒ recover
2. **Dependency on initial CoT:** Garbage in â†’ garbage out
3. **Latency overhead:** Extra VLM calls cho verification
4. **No real-time correction:** Post-hoc, not iterative

### Gá»£i Ã½ cho Future Work (tá»« Paper)

1. **RL for iterative refinement:** Real-time error correction
2. **RAG integration:** Ground reasoning trong external knowledge
3. **Lightweight verifiers:** Distilled models cho efficiency

---

## ğŸ”§ Recommendations cho Implementation

### Short-term (CÃ³ thá»ƒ lÃ m ngay)

1. **Add importance scoring** trong prompt synthesis:
   ```
   Evidence 1 (importance: 85%): "The person is wearing a red shirt"
   Evidence 2 (importance: 45%): "Background shows a park"
   ```

2. **Implement step-level bypass** cho pure reasoning steps:
   - Náº¿u step khÃ´ng chá»©a visual references â†’ skip evidence extraction

3. **Better error handling** khi grounding fails:
   - Fallback to full-image evidence

### Medium-term (Cáº§n thiáº¿t káº¿ thÃªm)

1. **Train lightweight relevance classifier:**
   - Input: reasoning step text
   - Output: visual_relevance_score [0, 1]
   - Data: Label tá»« manual annotation hoáº·c VLM self-assessment

2. **Add confidence calibration:**
   - Track accuracy cá»§a evidence vs final answer correctness
   - Adjust importance weights accordingly

### Long-term (Research direction)

1. **Iterative verification:**
   - After each step, verify vÃ  potentially revise
   - Requires streaming architecture

2. **Multi-modal RAG:**
   - Retrieve relevant images/documents for comparison
   - Cross-reference vá»›i external knowledge

---

## ğŸ“Š Summary Table

| Criterion | Score (1-5) | Comments |
|-----------|-------------|----------|
| **Novelty** | 4/5 | Good framing of single-look bias; post-hoc verification is practical |
| **Technical Soundness** | 4/5 | Well-designed ablations; clear methodology |
| **Reproducibility** | 4/5 | Details provided; uses public VLMs |
| **Impact** | 4/5 | Practical framework; immediate applicability |
| **Writing Quality** | 4/5 | Clear structure; good visualizations |

**Overall Assessment:** Paper Ä‘á» xuáº¥t má»™t framework practical vÃ  effective cho viá»‡c improve multimodal reasoning. Approach post-hoc verification lÃ  má»™t trade-off há»£p lÃ½ giá»¯a performance vÃ  complexity. Implementation cá»§a chÃºng ta Ä‘Ã£ capture Ä‘Æ°á»£c essence cá»§a paper vÃ  cÃ³ má»™t sá»‘ optimizations thÃªm (merged stages, smart routing).

---

## ğŸ“š References cho Deep Dive

1. **Chain-of-Thought:** Wei et al., 2022 - Foundational paper on CoT prompting
2. **Grounding DINO:** Liu et al., 2024 - Open-set object detection dÃ¹ng cho RoI selection
3. **Visual CoT:** Shao et al., 2024 - Dataset vá»›i bounding box annotations cho visual reasoning
4. **LLaVA-CoT:** Xu et al., 2024 - Structured multi-stage reasoning

---

*Review completed: December 2024*
